{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Programming Assignment 4 - Linear versus Ridge Regression-Fall 2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEMfOb2pC6O9"
      },
      "source": [
        "# Programming Assignment 4 - Linear versus Ridge Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiuZ5cbC6O-"
      },
      "source": [
        "The Boston housing data set was collected in the 1970s to study the relationship between house price and various factors such as the house size, crime rate, socio-economic status, etc. \n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gubvDdyUC6O_"
      },
      "source": [
        "In this notebook, you are to explore the effects of ridge regression.  We will use a dataset that is part of the sklearn.dataset package.  Learn more at https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv5UuueDC6O_"
      },
      "source": [
        "## Step 1:  Getting, understanding, and preprocessing the dataset\n",
        "\n",
        "We first import the standard libaries and some libraries that will help us scale the data and perform some \"feature engineering\" by transforming the data into $\\Phi_2({\\bf x})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZhRsNlSC6PA"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.linear_model\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuve0dE-C6PE"
      },
      "source": [
        "###  Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN9b-Ol-C6PE"
      },
      "source": [
        "# Import the boston dataset from sklearn\n",
        "boston_data = load_boston()"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYLJ6141C6PG",
        "outputId": "d68cfbe9-6145-487f-cb69-36e94412bc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "#  Create X and Y variables - X holding the design matrix and Y holding target vector\n",
        "X_orig = boston_data.data \n",
        "y = boston_data.target\n",
        "\n",
        "# Proprocesing by adding a column of 1's to the front of X_orig to create X\n",
        "one_col = np.ones((X_orig.shape[0],1))\n",
        "X = np.hstack((one_col, X_orig))\n",
        "\n",
        "#  Reshape Y to be a rank 2 matrix \n",
        "y = y.reshape(X_orig.shape[0], 1)\n",
        "\n",
        "# Observe the number of features and the number of labels\n",
        "print('The number of features +1 (for the intercept) is: ', X.shape[1])\n",
        "# Printing out the features\n",
        "print('The features: ', boston_data.feature_names)\n",
        "# The number of examples\n",
        "print('The number of exampels in our dataset: ', X.shape[0])\n",
        "#Observing the first 2 rows of the data\n",
        "print(X[0:2])\n"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of features +1 (for the intercept) is:  14\n",
            "The features:  ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n",
            "The number of exampels in our dataset:  506\n",
            "[[1.0000e+00 6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01\n",
            "  6.5750e+00 6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01\n",
            "  3.9690e+02 4.9800e+00]\n",
            " [1.0000e+00 2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01\n",
            "  6.4210e+00 7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01\n",
            "  3.9690e+02 9.1400e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt7eD3HjC6PJ"
      },
      "source": [
        "Since we will test linear and ridge regression on data with degree = 1 and data with degree = 2, we next create polynomial features of  degree 2 using the original dataset.  Feel free to increase the # of degress and see what effect it has on the training and test error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juuW6-NfC6PK"
      },
      "source": [
        "# Create a PolynomialFeatures object with degree = 2. \n",
        "# Transform X and save it into X_2. Simply copy Y into Y_2 \n",
        "# Note: PolynomialFeatures creates a column of ones as the first feature\n",
        "poly = PolynomialFeatures(degree=2,include_bias = True) \n",
        "X_2 = poly.fit_transform(X_orig)\n",
        "y_2 = y"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9e4tm88C6PM",
        "outputId": "066ee942-c94d-45e3-91ef-929c1264624e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# the shape of X_2 and Y_2 - should be (506, 105) and (506, 1) respectively\n",
        "print(X.shape)\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 14)\n",
            "(506, 105)\n",
            "(506, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTKo4R3mC6PO"
      },
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jKUMKzboQ9T"
      },
      "source": [
        "#linear regression\n",
        "def linear_reg(X_train,y_train,alpha):\n",
        "  psd_inverse = np.linalg.pinv(X_train)\n",
        "  wlin = np.dot(psd_inverse, y_train)\n",
        "  return wlin"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inppc3IC6PP"
      },
      "source": [
        "# TODO - Define the get_coeff_ridge_normaleq function. \n",
        "# Use the normal equation method.\n",
        "# TODO - Return w values\n",
        "\n",
        "def get_coeff_ridge_normaleq(X_train, y_train, alpha):\n",
        "    # use np.linalg.pinv(a)\n",
        "    #### TO-DO #####\n",
        "    Xt = np.transpose(X_train)\n",
        "    #print(Xt.shape)\n",
        "    #print(Xt.shape)\n",
        "    #print(X_train.shape)\n",
        "    XtX = np.dot(Xt,X_train)\n",
        "    #print(XtX.shape)\n",
        "    N = X_train.shape[0]\n",
        "    I = np.identity(X_train.shape[1])\n",
        "    \n",
        "    I.itemset((0,0),0)\n",
        "    #print(I)\n",
        "    #print(I.shape)\n",
        "    N_alpa_I = N*alpha*I\n",
        "    part1 = np.linalg.inv(XtX+N_alpa_I)\n",
        "    w = np.dot(np.dot(part1,Xt),y_train)\n",
        "    ##############\n",
        "    return w"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs-NgFMqC6PS"
      },
      "source": [
        "# TODO - Define the evaluate_err_ridge function.\n",
        "# TODO - Return the train_error and test_error values\n",
        "\n",
        "def evaluate_err(X_train, X_test, y_train, y_test, w): \n",
        "    #### TO-DO #####\n",
        "    y_train_hat =  np.dot(X_train,w)\n",
        "    y_test_hat = np.dot(X_test,w)\n",
        "    n_train = X_train.shape[0]\n",
        "    n_test = X_test.shape[0]\n",
        "    temp_tr = np.power((y_train_hat-y_train),2)\n",
        "    temp_ts = np.power((y_test_hat-y_test),2)\n",
        "    MSE_tr = np.sum(temp_tr, axis=0)/n_train\n",
        "    MSE_ts = np.sum(temp_ts, axis=0)/n_test\n",
        "    ##############\n",
        "    return MSE_tr, MSE_ts"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8e2Y6qiC6PU"
      },
      "source": [
        "# TODO - Finish writting the k_fold_cross_validation function. \n",
        "# TODO - Returns the average training error and average test error from the k-fold cross validation\n",
        "# use Sklearns K-Folds cross-validator: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "\n",
        "def k_fold_cross_validation(k, X, y, alpha,regression_model):\n",
        "    kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
        "    total_E_val_test = 0\n",
        "    total_E_val_train = 0\n",
        "    n = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        n=n+1\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        # scaling the data matrix (except for for the first column of ones)\n",
        "        scaler = preprocessing.StandardScaler().fit(X_train[:,1:(X_train.shape[1]+1)])\n",
        "        X_train[:,1:(X_train.shape[1]+1)] = scaler.transform(X_train[:,1:(X_train.shape[1]+1)])\n",
        "        X_test[:,1:(X_train.shape[1]+1)] = scaler.transform(X_test[:,1:(X_train.shape[1]+1)])\n",
        "\n",
        "        \n",
        "        # determine the training error and the test error\n",
        "        #### TO-DO #####\n",
        "        print(n,\"folds\")\n",
        "        w = regression_model(X_train,y_train,alpha)\n",
        "        MSE_tr,MSE_ts = evaluate_err(X_train,X_test,y_train,y_test,w)\n",
        "        print(\"train MSE\",MSE_tr)\n",
        "        print(\"validation MSE\",MSE_ts)\n",
        "        total_E_val_test = total_E_val_test+MSE_ts\n",
        "        total_E_val_train = total_E_val_train +MSE_tr\n",
        "    E_val_test = total_E_val_test/k\n",
        "    E_val_train = total_E_val_train/k\n",
        "       ##############\n",
        "    return  E_val_test, E_val_train\n",
        "    \n"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y-Ab-WAC6PW",
        "outputId": "dfed9f6c-666c-41c6-804d-0e07ecdb904d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "alpha = np.logspace(-5, 1, num=15)\n",
        "print(alpha)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00000000e-05 2.68269580e-05 7.19685673e-05 1.93069773e-04\n",
            " 5.17947468e-04 1.38949549e-03 3.72759372e-03 1.00000000e-02\n",
            " 2.68269580e-02 7.19685673e-02 1.93069773e-01 5.17947468e-01\n",
            " 1.38949549e+00 3.72759372e+00 1.00000000e+01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jkSvAnOJzWu"
      },
      "source": [
        "linear regression with X and X_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhlfhMaGB5nt",
        "outputId": "e5952dd1-d347-421e-b996-fe1369b2de48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "#linear regression\n",
        "# x,y\n",
        "E_val_test,E_val_train = k_fold_cross_validation(3,X,y,0,linear_reg)\n",
        "print(\"avarage MSE of test\",E_val_train)\n",
        "print(\"avarage MSE of test\",E_val_test)\n",
        "# x_2,y_2\n",
        "print(\" creating a polynomial transformation\")\n",
        "E_val_test,E_val_train = k_fold_cross_validation(3,X_2,y_2,0,linear_reg)\n",
        "print(\"avarage MSE of train\",E_val_train)\n",
        "print(\"avarage MSE of test\",E_val_test)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 folds\n",
            "train MSE [20.17653041]\n",
            "validation MSE [26.94958751]\n",
            "2 folds\n",
            "train MSE [22.33224469]\n",
            "validation MSE [22.7337]\n",
            "3 folds\n",
            "train MSE [21.96992282]\n",
            "validation MSE [22.32462086]\n",
            "avarage MSE of test [21.4928993]\n",
            "avarage MSE of test [24.00263612]\n",
            " creating a polynomial transformation\n",
            "1 folds\n",
            "train MSE [5.34590153]\n",
            "validation MSE [12.34962204]\n",
            "2 folds\n",
            "train MSE [5.93695452]\n",
            "validation MSE [11.87848315]\n",
            "3 folds\n",
            "train MSE [3.93532048]\n",
            "validation MSE [19.56397323]\n",
            "avarage MSE of train [5.07272551]\n",
            "avarage MSE of test [14.59735947]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf2NwtWCKQtV"
      },
      "source": [
        "ridge regression with x and x_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHkIpHPR-9Ic",
        "outputId": "560a0e57-7169-4521-be9d-00e105a534a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#ridge regression for x,y\n",
        "for a in alpha:\n",
        "  print(\"alpha=\",a)\n",
        "  E_val_test,E_val_train = k_fold_cross_validation(3,X,y,a,get_coeff_ridge_normaleq)\n",
        "  print(\"avarage MSE of train\",E_val_train)\n",
        "  print(\"avarage MSE of test\",E_val_test)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha= 1e-05\n",
            "1 folds\n",
            "train MSE [20.17653044]\n",
            "validation MSE [26.9494752]\n",
            "2 folds\n",
            "train MSE [22.33224472]\n",
            "validation MSE [22.73357472]\n",
            "3 folds\n",
            "train MSE [21.96992285]\n",
            "validation MSE [22.32449699]\n",
            "avarage MSE of train [21.49289933]\n",
            "avarage MSE of test [24.00251564]\n",
            "alpha= 2.6826957952797274e-05\n",
            "1 folds\n",
            "train MSE [20.17653061]\n",
            "validation MSE [26.94928636]\n",
            "2 folds\n",
            "train MSE [22.33224489]\n",
            "validation MSE [22.73336408]\n",
            "3 folds\n",
            "train MSE [21.96992305]\n",
            "validation MSE [22.32428881]\n",
            "avarage MSE of train [21.49289952]\n",
            "avarage MSE of test [24.00231308]\n",
            "alpha= 7.196856730011514e-05\n",
            "1 folds\n",
            "train MSE [20.17653189]\n",
            "validation MSE [26.94878067]\n",
            "2 folds\n",
            "train MSE [22.33224614]\n",
            "validation MSE [22.73279997]\n",
            "3 folds\n",
            "train MSE [21.96992444]\n",
            "validation MSE [22.32373195]\n",
            "avarage MSE of train [21.49290083]\n",
            "avarage MSE of test [24.00177086]\n",
            "alpha= 0.00019306977288832496\n",
            "1 folds\n",
            "train MSE [20.17654108]\n",
            "validation MSE [26.94743065]\n",
            "2 folds\n",
            "train MSE [22.33225512]\n",
            "validation MSE [22.73129366]\n",
            "3 folds\n",
            "train MSE [21.96993448]\n",
            "validation MSE [22.32224955]\n",
            "avarage MSE of train [21.49291023]\n",
            "avarage MSE of test [24.00032462]\n",
            "alpha= 0.0005179474679231213\n",
            "1 folds\n",
            "train MSE [20.17660667]\n",
            "validation MSE [26.94385589]\n",
            "2 folds\n",
            "train MSE [22.33231921]\n",
            "validation MSE [22.72730262]\n",
            "3 folds\n",
            "train MSE [21.97000604]\n",
            "validation MSE [22.31835452]\n",
            "avarage MSE of train [21.49297731]\n",
            "avarage MSE of test [23.99650434]\n",
            "alpha= 0.0013894954943731374\n",
            "1 folds\n",
            "train MSE [20.1770691]\n",
            "validation MSE [26.93459619]\n",
            "2 folds\n",
            "train MSE [22.33277006]\n",
            "validation MSE [22.71694508]\n",
            "3 folds\n",
            "train MSE [21.97050853]\n",
            "validation MSE [22.30847574]\n",
            "avarage MSE of train [21.49344923]\n",
            "avarage MSE of test [23.98667234]\n",
            "alpha= 0.003727593720314938\n",
            "1 folds\n",
            "train MSE [20.18022246]\n",
            "validation MSE [26.9119966]\n",
            "2 folds\n",
            "train MSE [22.33582887]\n",
            "validation MSE [22.69149092]\n",
            "3 folds\n",
            "train MSE [21.97390041]\n",
            "validation MSE [22.28575113]\n",
            "avarage MSE of train [21.49665058]\n",
            "avarage MSE of test [23.96307955]\n",
            "alpha= 0.01\n",
            "1 folds\n",
            "train MSE [20.2000483]\n",
            "validation MSE [26.86527439]\n",
            "2 folds\n",
            "train MSE [22.35484457]\n",
            "validation MSE [22.63711446]\n",
            "3 folds\n",
            "train MSE [21.99472009]\n",
            "validation MSE [22.24678686]\n",
            "avarage MSE of train [21.51653765]\n",
            "avarage MSE of test [23.9163919]\n",
            "alpha= 0.026826957952797246\n",
            "1 folds\n",
            "train MSE [20.30489029]\n",
            "validation MSE [26.81081211]\n",
            "2 folds\n",
            "train MSE [22.45357993]\n",
            "validation MSE [22.55644107]\n",
            "3 folds\n",
            "train MSE [22.09982066]\n",
            "validation MSE [22.23824731]\n",
            "avarage MSE of train [21.61943029]\n",
            "avarage MSE of test [23.86850016]\n",
            "alpha= 0.07196856730011514\n",
            "1 folds\n",
            "train MSE [20.72345742]\n",
            "validation MSE [26.9211329]\n",
            "2 folds\n",
            "train MSE [22.84369958]\n",
            "validation MSE [22.54704021]\n",
            "3 folds\n",
            "train MSE [22.49760674]\n",
            "validation MSE [22.46103406]\n",
            "avarage MSE of train [22.02158791]\n",
            "avarage MSE of test [23.97640239]\n",
            "alpha= 0.19306977288832497\n",
            "1 folds\n",
            "train MSE [21.96967034]\n",
            "validation MSE [27.82845446]\n",
            "2 folds\n",
            "train MSE [24.03934272]\n",
            "validation MSE [22.96950038]\n",
            "3 folds\n",
            "train MSE [23.68843553]\n",
            "validation MSE [23.37822297]\n",
            "avarage MSE of train [23.23248286]\n",
            "avarage MSE of test [24.7253926]\n",
            "alpha= 0.5179474679231213\n",
            "1 folds\n",
            "train MSE [25.08532695]\n",
            "validation MSE [31.23809919]\n",
            "2 folds\n",
            "train MSE [27.28232349]\n",
            "validation MSE [24.91451833]\n",
            "3 folds\n",
            "train MSE [26.90760795]\n",
            "validation MSE [26.12264275]\n",
            "avarage MSE of train [26.42508613]\n",
            "avarage MSE of test [27.42508676]\n",
            "alpha= 1.389495494373136\n",
            "1 folds\n",
            "train MSE [31.66860266]\n",
            "validation MSE [39.80310001]\n",
            "2 folds\n",
            "train MSE [34.82654591]\n",
            "validation MSE [30.63735468]\n",
            "3 folds\n",
            "train MSE [34.21880317]\n",
            "validation MSE [32.46994807]\n",
            "avarage MSE of train [33.57131725]\n",
            "avarage MSE of test [34.30346759]\n",
            "alpha= 3.727593720314938\n",
            "1 folds\n",
            "train MSE [42.14091329]\n",
            "validation MSE [53.64985198]\n",
            "2 folds\n",
            "train MSE [47.20290947]\n",
            "validation MSE [41.36562242]\n",
            "3 folds\n",
            "train MSE [46.23184325]\n",
            "validation MSE [42.5465427]\n",
            "avarage MSE of train [45.19188867]\n",
            "avarage MSE of test [45.8540057]\n",
            "alpha= 10.0\n",
            "1 folds\n",
            "train MSE [54.92761048]\n",
            "validation MSE [69.53144239]\n",
            "2 folds\n",
            "train MSE [61.62733639]\n",
            "validation MSE [55.11657452]\n",
            "3 folds\n",
            "train MSE [60.89028033]\n",
            "validation MSE [54.67456063]\n",
            "avarage MSE of train [59.14840907]\n",
            "avarage MSE of test [59.77419252]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f2jFheOCkUF",
        "outputId": "3d1195a6-b2c9-4b02-d14f-a116dc208342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#ridge regression for X_2,y_2\n",
        "E_test=[]\n",
        "E_train=[]\n",
        "for a in alpha:\n",
        "  print(\"alpha=\",a)\n",
        "  E_val_test,E_val_train = k_fold_cross_validation(3,X_2,y_2,a,get_coeff_ridge_normaleq)\n",
        "  print(\"avarage MSE of test\",E_val_train)\n",
        "  print(\"avarage MSE of test\",E_val_test)\n",
        "  E_test.append(E_val_test)\n",
        "  E_train.append(E_val_train)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha= 1e-05\n",
            "1 folds\n",
            "train MSE [5.39208602]\n",
            "validation MSE [12.24073343]\n",
            "2 folds\n",
            "train MSE [5.986366]\n",
            "validation MSE [11.44422058]\n",
            "3 folds\n",
            "train MSE [3.99797872]\n",
            "validation MSE [17.34791157]\n",
            "avarage MSE of test [5.12547691]\n",
            "avarage MSE of test [13.67762186]\n",
            "alpha= 2.6826957952797274e-05\n",
            "1 folds\n",
            "train MSE [5.46019444]\n",
            "validation MSE [12.15387609]\n",
            "2 folds\n",
            "train MSE [6.0475875]\n",
            "validation MSE [11.19066572]\n",
            "3 folds\n",
            "train MSE [4.06333095]\n",
            "validation MSE [16.56781799]\n",
            "avarage MSE of test [5.19037096]\n",
            "avarage MSE of test [13.30411993]\n",
            "alpha= 7.196856730011514e-05\n",
            "1 folds\n",
            "train MSE [5.60492139]\n",
            "validation MSE [12.09264754]\n",
            "2 folds\n",
            "train MSE [6.17604732]\n",
            "validation MSE [10.93600132]\n",
            "3 folds\n",
            "train MSE [4.18151193]\n",
            "validation MSE [16.09057591]\n",
            "avarage MSE of test [5.32082688]\n",
            "avarage MSE of test [13.03974159]\n",
            "alpha= 0.00019306977288832496\n",
            "1 folds\n",
            "train MSE [5.87002822]\n",
            "validation MSE [12.03862141]\n",
            "2 folds\n",
            "train MSE [6.40551953]\n",
            "validation MSE [10.74345732]\n",
            "3 folds\n",
            "train MSE [4.38654182]\n",
            "validation MSE [15.85383091]\n",
            "avarage MSE of test [5.55402986]\n",
            "avarage MSE of test [12.87863654]\n",
            "alpha= 0.0005179474679231213\n",
            "1 folds\n",
            "train MSE [6.30171474]\n",
            "validation MSE [11.83798123]\n",
            "2 folds\n",
            "train MSE [6.76750804]\n",
            "validation MSE [10.68095954]\n",
            "3 folds\n",
            "train MSE [4.71157302]\n",
            "validation MSE [15.75445392]\n",
            "avarage MSE of test [5.92693193]\n",
            "avarage MSE of test [12.75779823]\n",
            "alpha= 0.0013894954943731374\n",
            "1 folds\n",
            "train MSE [6.93958726]\n",
            "validation MSE [11.28710097]\n",
            "2 folds\n",
            "train MSE [7.29123209]\n",
            "validation MSE [10.68950158]\n",
            "3 folds\n",
            "train MSE [5.15870435]\n",
            "validation MSE [15.79185432]\n",
            "avarage MSE of test [6.46317457]\n",
            "avarage MSE of test [12.58948562]\n",
            "alpha= 0.003727593720314938\n",
            "1 folds\n",
            "train MSE [7.86914073]\n",
            "validation MSE [10.66892422]\n",
            "2 folds\n",
            "train MSE [8.06238967]\n",
            "validation MSE [10.67183354]\n",
            "3 folds\n",
            "train MSE [5.77644837]\n",
            "validation MSE [16.0106062]\n",
            "avarage MSE of test [7.23599292]\n",
            "avarage MSE of test [12.45045465]\n",
            "alpha= 0.01\n",
            "1 folds\n",
            "train MSE [9.16152366]\n",
            "validation MSE [10.80862973]\n",
            "2 folds\n",
            "train MSE [9.19300397]\n",
            "validation MSE [11.055446]\n",
            "3 folds\n",
            "train MSE [6.71466783]\n",
            "validation MSE [16.37935113]\n",
            "avarage MSE of test [8.35639849]\n",
            "avarage MSE of test [12.74780895]\n",
            "alpha= 0.026826957952797246\n",
            "1 folds\n",
            "train MSE [10.90934578]\n",
            "validation MSE [12.53876873]\n",
            "2 folds\n",
            "train MSE [10.81898146]\n",
            "validation MSE [12.43993532]\n",
            "3 folds\n",
            "train MSE [8.30791305]\n",
            "validation MSE [17.16725258]\n",
            "avarage MSE of test [10.0120801]\n",
            "avarage MSE of test [14.04865221]\n",
            "alpha= 0.07196856730011514\n",
            "1 folds\n",
            "train MSE [13.27110099]\n",
            "validation MSE [16.05381453]\n",
            "2 folds\n",
            "train MSE [13.14961154]\n",
            "validation MSE [14.92575729]\n",
            "3 folds\n",
            "train MSE [10.92893043]\n",
            "validation MSE [18.88667671]\n",
            "avarage MSE of test [12.44988098]\n",
            "avarage MSE of test [16.62208284]\n",
            "alpha= 0.19306977288832497\n",
            "1 folds\n",
            "train MSE [15.92306797]\n",
            "validation MSE [20.1843312]\n",
            "2 folds\n",
            "train MSE [15.93778182]\n",
            "validation MSE [17.58320802]\n",
            "3 folds\n",
            "train MSE [14.15987622]\n",
            "validation MSE [20.92377613]\n",
            "avarage MSE of test [15.340242]\n",
            "avarage MSE of test [19.56377178]\n",
            "alpha= 0.5179474679231213\n",
            "1 folds\n",
            "train MSE [18.4086415]\n",
            "validation MSE [23.84602267]\n",
            "2 folds\n",
            "train MSE [18.90035143]\n",
            "validation MSE [19.57440545]\n",
            "3 folds\n",
            "train MSE [17.41964833]\n",
            "validation MSE [22.42220401]\n",
            "avarage MSE of test [18.24288042]\n",
            "avarage MSE of test [21.94754404]\n",
            "alpha= 1.389495494373136\n",
            "1 folds\n",
            "train MSE [21.24851098]\n",
            "validation MSE [27.58929684]\n",
            "2 folds\n",
            "train MSE [22.59055702]\n",
            "validation MSE [21.56839855]\n",
            "3 folds\n",
            "train MSE [21.20274598]\n",
            "validation MSE [23.98010368]\n",
            "avarage MSE of test [21.68060466]\n",
            "avarage MSE of test [24.37926636]\n",
            "alpha= 3.727593720314938\n",
            "1 folds\n",
            "train MSE [26.18308839]\n",
            "validation MSE [33.87729368]\n",
            "2 folds\n",
            "train MSE [28.52877026]\n",
            "validation MSE [25.60319732]\n",
            "3 folds\n",
            "train MSE [27.20232144]\n",
            "validation MSE [27.60518383]\n",
            "avarage MSE of test [27.3047267]\n",
            "avarage MSE of test [29.02855827]\n",
            "alpha= 10.0\n",
            "1 folds\n",
            "train MSE [34.76530326]\n",
            "validation MSE [45.02298466]\n",
            "2 folds\n",
            "train MSE [38.5097124]\n",
            "validation MSE [33.73873818]\n",
            "3 folds\n",
            "train MSE [37.24706694]\n",
            "validation MSE [35.32380721]\n",
            "avarage MSE of test [36.8406942]\n",
            "avarage MSE of test [38.02851002]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IECM2J9wLEZm",
        "outputId": "427ddc00-70f9-466e-cca1-96761283fa06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,10))\n",
        "x = alpha\n",
        "plt.plot(x,E_test,'s-',color = 'r',label=\"E_test\")\n",
        "plt.plot(x,E_train,'s-',color = 'g',label=\"E_train\")\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"E_val\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr7Oh3CrJudb"
      },
      "source": [
        "###experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kbKNxmUfl3g",
        "outputId": "ad023a7f-0172-434f-dbf3-ded1d73415b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "poly = PolynomialFeatures(degree=3,include_bias = True) \n",
        "X_3 = poly.fit_transform(X_orig)\n",
        "y_3 = y\n",
        "E_val_test,E_val_train = k_fold_cross_validation(3,X_3,y_3,25,get_coeff_ridge_normaleq)\n",
        "print(\"avarage MSE of train\",E_val_train)\n",
        "print(\"avarage MSE of test\",E_val_test)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 folds\n",
            "train MSE [30.81786627]\n",
            "validation MSE [40.22102252]\n",
            "2 folds\n",
            "train MSE [33.49343836]\n",
            "validation MSE [30.53616379]\n",
            "3 folds\n",
            "train MSE [32.01528506]\n",
            "validation MSE [32.20253892]\n",
            "avarage MSE of train [32.10886323]\n",
            "avarage MSE of test [34.31990841]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB_MwBkRJt-y",
        "outputId": "4d646008-5832-4523-e35d-bf0eaf5d2fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for a in alpha:\n",
        "  print(\"alpha=\",a)\n",
        "  E_val_test,E_val_train = k_fold_cross_validation(3,X_3,y_3,a,get_coeff_ridge_normaleq)\n",
        "  print(\"avarage MSE of test\",E_val_train)\n",
        "  print(\"avarage MSE of test\",E_val_test)\n",
        "  E_test.append(E_val_test)\n",
        "  E_train.append(E_val_train)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha= 1e-05\n",
            "1 folds\n",
            "train MSE [0.71537819]\n",
            "validation MSE [99.97767571]\n",
            "2 folds\n",
            "train MSE [0.99067318]\n",
            "validation MSE [129.59584886]\n",
            "3 folds\n",
            "train MSE [0.7554781]\n",
            "validation MSE [56.19508925]\n",
            "avarage MSE of test [0.82050982]\n",
            "avarage MSE of test [95.25620461]\n",
            "alpha= 2.6826957952797274e-05\n",
            "1 folds\n",
            "train MSE [0.94928934]\n",
            "validation MSE [70.7000401]\n",
            "2 folds\n",
            "train MSE [1.35807964]\n",
            "validation MSE [64.11843252]\n",
            "3 folds\n",
            "train MSE [1.00077054]\n",
            "validation MSE [38.36143574]\n",
            "avarage MSE of test [1.10271317]\n",
            "avarage MSE of test [57.72663612]\n",
            "alpha= 7.196856730011514e-05\n",
            "1 folds\n",
            "train MSE [1.27172111]\n",
            "validation MSE [44.32856162]\n",
            "2 folds\n",
            "train MSE [1.83659379]\n",
            "validation MSE [35.82178173]\n",
            "3 folds\n",
            "train MSE [1.29133685]\n",
            "validation MSE [29.13196056]\n",
            "avarage MSE of test [1.46655058]\n",
            "avarage MSE of test [36.42743464]\n",
            "alpha= 0.00019306977288832496\n",
            "1 folds\n",
            "train MSE [1.70391688]\n",
            "validation MSE [26.9737708]\n",
            "2 folds\n",
            "train MSE [2.38964599]\n",
            "validation MSE [21.58799017]\n",
            "3 folds\n",
            "train MSE [1.62749772]\n",
            "validation MSE [23.87529103]\n",
            "avarage MSE of test [1.9070202]\n",
            "avarage MSE of test [24.145684]\n",
            "alpha= 0.0005179474679231213\n",
            "1 folds\n",
            "train MSE [2.22581225]\n",
            "validation MSE [19.27743669]\n",
            "2 folds\n",
            "train MSE [3.01818725]\n",
            "validation MSE [13.53236781]\n",
            "3 folds\n",
            "train MSE [2.00052729]\n",
            "validation MSE [20.24150005]\n",
            "avarage MSE of test [2.41484226]\n",
            "avarage MSE of test [17.68376818]\n",
            "alpha= 0.0013894954943731374\n",
            "1 folds\n",
            "train MSE [2.83055566]\n",
            "validation MSE [15.85099418]\n",
            "2 folds\n",
            "train MSE [3.78395697]\n",
            "validation MSE [9.49963328]\n",
            "3 folds\n",
            "train MSE [2.45257411]\n",
            "validation MSE [17.26664942]\n",
            "avarage MSE of test [3.02236225]\n",
            "avarage MSE of test [14.20575896]\n",
            "alpha= 0.003727593720314938\n",
            "1 folds\n",
            "train MSE [3.61123428]\n",
            "validation MSE [13.57165493]\n",
            "2 folds\n",
            "train MSE [4.72232687]\n",
            "validation MSE [8.34813323]\n",
            "3 folds\n",
            "train MSE [3.10120597]\n",
            "validation MSE [15.55562404]\n",
            "avarage MSE of test [3.81158904]\n",
            "avarage MSE of test [12.49180407]\n",
            "alpha= 0.01\n",
            "1 folds\n",
            "train MSE [4.69245608]\n",
            "validation MSE [11.75462848]\n",
            "2 folds\n",
            "train MSE [5.78604089]\n",
            "validation MSE [8.89918693]\n",
            "3 folds\n",
            "train MSE [3.98781291]\n",
            "validation MSE [15.55488793]\n",
            "avarage MSE of test [4.82210329]\n",
            "avarage MSE of test [12.06956778]\n",
            "alpha= 0.026826957952797246\n",
            "1 folds\n",
            "train MSE [6.13187091]\n",
            "validation MSE [10.55890158]\n",
            "2 folds\n",
            "train MSE [6.95927557]\n",
            "validation MSE [9.87846472]\n",
            "3 folds\n",
            "train MSE [5.00761487]\n",
            "validation MSE [16.34118164]\n",
            "avarage MSE of test [6.03292045]\n",
            "avarage MSE of test [12.25951598]\n",
            "alpha= 0.07196856730011514\n",
            "1 folds\n",
            "train MSE [7.95990706]\n",
            "validation MSE [10.41232615]\n",
            "2 folds\n",
            "train MSE [8.34619154]\n",
            "validation MSE [10.90228864]\n",
            "3 folds\n",
            "train MSE [6.19234186]\n",
            "validation MSE [16.92246802]\n",
            "avarage MSE of test [7.49948016]\n",
            "avarage MSE of test [12.74569427]\n",
            "alpha= 0.19306977288832497\n",
            "1 folds\n",
            "train MSE [10.20810947]\n",
            "validation MSE [11.87064023]\n",
            "2 folds\n",
            "train MSE [10.1373655]\n",
            "validation MSE [12.43907726]\n",
            "3 folds\n",
            "train MSE [7.85718361]\n",
            "validation MSE [17.42153594]\n",
            "avarage MSE of test [9.40088619]\n",
            "avarage MSE of test [13.91041781]\n",
            "alpha= 0.5179474679231213\n",
            "1 folds\n",
            "train MSE [12.98309467]\n",
            "validation MSE [15.37663232]\n",
            "2 folds\n",
            "train MSE [12.6348088]\n",
            "validation MSE [14.85764658]\n",
            "3 folds\n",
            "train MSE [10.51486999]\n",
            "validation MSE [18.87375566]\n",
            "avarage MSE of test [12.04425782]\n",
            "avarage MSE of test [16.36934485]\n",
            "alpha= 1.389495494373136\n",
            "1 folds\n",
            "train MSE [16.22770505]\n",
            "validation MSE [20.36538569]\n",
            "2 folds\n",
            "train MSE [15.9982693]\n",
            "validation MSE [17.80044735]\n",
            "3 folds\n",
            "train MSE [14.17960984]\n",
            "validation MSE [21.44456273]\n",
            "avarage MSE of test [15.46852806]\n",
            "avarage MSE of test [19.87013193]\n",
            "alpha= 3.727593720314938\n",
            "1 folds\n",
            "train MSE [19.76988897]\n",
            "validation MSE [25.79038711]\n",
            "2 folds\n",
            "train MSE [20.25489671]\n",
            "validation MSE [20.87658046]\n",
            "3 folds\n",
            "train MSE [18.5393897]\n",
            "validation MSE [24.12379164]\n",
            "avarage MSE of test [19.52139179]\n",
            "avarage MSE of test [23.59691974]\n",
            "alpha= 10.0\n",
            "1 folds\n",
            "train MSE [24.31735169]\n",
            "validation MSE [31.98910798]\n",
            "2 folds\n",
            "train MSE [25.8891584]\n",
            "validation MSE [24.75718802]\n",
            "3 folds\n",
            "train MSE [24.23747243]\n",
            "validation MSE [27.20897582]\n",
            "avarage MSE of test [24.81466084]\n",
            "avarage MSE of test [27.98509061]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyzLp0qbKlaq"
      },
      "source": [
        "predict the average price of a house"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2SgX7ZGtFd",
        "outputId": "fbbb3dbc-f28b-4e1e-da74-4ce6b340e99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predict_X=[ 0.1, 11, 7, 0, 0.4, 6, 70, 4, 6, 300, 16, 360, 10]\n",
        "predict_X = np.asarray(predict_X)\n",
        "predict_X = predict_X.reshape(1,13)\n",
        "\n",
        "poly = PolynomialFeatures(degree=2,include_bias = True) \n",
        "predict_X_2 = poly.fit_transform(predict_X)\n",
        "#print(predict_X_2)\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X_2[:,1:(X_2.shape[1]+1)])\n",
        "X_2[:,1:(X_2.shape[1]+1)] =  scaler.transform(X_2[:,1:(X_2.shape[1]+1)])\n",
        "predict_X_2[:,1:(X_2.shape[1]+1)] =  scaler.transform(predict_X_2[:,1:(X_2.shape[1]+1)])\n",
        "\n",
        "w_2 = get_coeff_ridge_normaleq(X_2,y_2,0.01)\n",
        "predict_y = np.dot(predict_X_2,w_2)\n",
        "print(predict_y)\n"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[24.67886008]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
